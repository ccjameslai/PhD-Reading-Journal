import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from tom_utility import *

def evaluate_tomnet(model, num_samples=5, alpha=0.01):
    env = Gridworld()
    agent = RandomAgent(alpha)
    agent.reset()
    past_data = []

    # è’é›† Npast ç­†è³‡æ–™
    for _ in range(num_samples):
        state = env.reset()
        obs = agent.observe(state)
        action = agent.act(obs)
        past_data.append((state, action))

    # é¸æ“‡æŸ¥è©¢ç‹€æ…‹ï¼ˆToMnet é æ¸¬ç›®æ¨™ï¼‰
    query_state = env.reset()

    # ä½¿ç”¨æœ€å¾Œä¸€ç­†éå»è¡Œç‚ºç•¶ä½œ inputï¼ˆå¯å‡ç´šç‚ºå¹³å‡æˆ– LSTMï¼‰
    last_state, last_action = past_data[-1]
    state_tensor = torch.tensor(last_state, dtype=torch.float32).unsqueeze(0)
    action_tensor = F.one_hot(torch.tensor(
        last_action), 5).float().unsqueeze(0)
    query_tensor = torch.tensor(query_state, dtype=torch.float32).unsqueeze(0)

    # ToMnet é æ¸¬
    with torch.no_grad():
        logits = model(state_tensor, action_tensor, query_tensor)
        probs = F.softmax(logits, dim=-1)
        predicted_action = torch.argmax(probs, dim=-1).item()

    # é¡¯ç¤ºåŸºæœ¬è³‡è¨Š
    print("ğŸ” ToMnet prediction:")
    print(f" - distributions of actions: {probs.squeeze().numpy().round(3)}")
    print(
        f" - predicted action index: {predicted_action}ï¼ˆâ†=0, â†’=1, â†‘=2, â†“=3, Â·=4ï¼‰")

    # åŠ å…¥å¯è¦–åŒ–
    print("ğŸ—ºï¸ Query Gridworld:")
    # visualize_gridworld_with_action(query_tensor.squeeze().numpy(), predicted_action, title="ToMnet visualization")

    visualize_gridworld_with_history(
        query_tensor.squeeze().numpy(),
        predicted_action,
        [s for s, _ in past_data],
        [a for _, a in past_data],
        title="ToMnet visualization"
    )

    return predicted_action, probs


# è©•ä¼° ToMnet å° mixture species çš„é æ¸¬å“è³ªï¼ˆç”¨ KL divergence)
def evaluate_tomnet_on_mixture(model, alpha_low=0.01, alpha_high=3.0, ratio=0.5, npast=5, num_test_agents=200):
    kl_values = []
    env = Gridworld()

    for _ in range(num_test_agents):
        alpha = alpha_low if np.random.rand() < ratio else alpha_high
        agent = RandomAgent(alpha)
        pi_true = agent.pi

        past_states, past_actions = [], []
        for _ in range(npast):
            s = env.reset()
            obs = agent.observe(s)
            a = agent.act(obs)
            past_states.append(s)
            past_actions.append(np.eye(5)[a])

        query_state = env.reset()

        s_tensor = torch.tensor(np.stack(past_states), dtype=torch.float32).unsqueeze(0)
        a_tensor = torch.tensor(np.stack(past_actions), dtype=torch.float32).unsqueeze(0)
        q_tensor = torch.tensor(query_state, dtype=torch.float32).unsqueeze(0)

        with torch.no_grad():
            logits = model(s_tensor, a_tensor, q_tensor)
            probs = F.softmax(logits, dim=-1).squeeze().numpy()

        kl = np.sum(pi_true * (np.log(pi_true + 1e-8) - np.log(probs + 1e-8)))
        kl_values.append(kl)

    return np.mean(kl_values)

# è¦–è¦ºåŒ–å…©ç¨®å–®ä¸€ species èˆ‡æ··åˆ species æ¨¡å‹åœ¨ä¸åŒæ¸¬è©¦ä¸Šçš„ KL æ•ˆæœ
def plot_figure3d_kl_bars(kl_001_on_001, kl_3_on_3, kl_mix_on_mix):
    labels = ['ToMnet@Î±=0.01', 'ToMnet@Î±=3.0', 'ToMnet@Mixture']
    values = [kl_001_on_001, kl_3_on_3, kl_mix_on_mix]

    plt.figure(figsize=(8, 5))
    bars = plt.bar(labels, values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
    plt.title("Figure 3d: KL divergence on mixture agents")
    plt.ylabel("KL Divergence (lower is better)")
    for bar, val in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() +
                 0.01, f"{val:.3f}", ha='center', va='bottom')
    plt.ylim(0, max(values) * 1.2)
    plt.grid(True, axis='y', linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.show()

def plot_figure3d_kl_lines(kl_001_on_001, kl_3_on_3, kl_mix_on_mix):
    # å‡è¨­çš„ Test Î± å€¼
    test_alphas = [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]

    # æ¨¡æ“¬çš„ ToMnet é æ¸¬ KL æ•£åº¦æ•¸å€¼
    kl_trained_001 = kl_001_on_001
    kl_trained_3 = kl_3_on_3
    kl_trained_mix = kl_mix_on_mix

    plt.figure(figsize=(4, 4))

    # ç•«åœ–
    plt.plot(test_alphas, kl_trained_001, '-o', color='black', label='Trained Î±=0.01')
    plt.plot(test_alphas, kl_trained_3, '-o', color='skyblue', label='Trained Î±=3')
    plt.plot(test_alphas, kl_trained_mix, '-s', color='firebrick', label='Trained Î±=0.01,3')

    # æ¨™ç¤º
    plt.xscale('log')
    plt.xlabel('Test Î±')
    plt.ylabel('KL Divergence')
    plt.title('KL Divergence (5 obs.)')

    plt.legend(title='Trained Î±')
    plt.grid(True, linestyle='--', alpha=0.4)
    plt.tight_layout()
    plt.show()


def exp_3_1_grid():
    
    model = ToMnet()

    if not torch.load(r"trained_model\tomnet.pth"):
        # === è¨“ç·´éšæ®µ ===
        train_tomnet()

    # === æ¨è«–éšæ®µ ===
    model.load_state_dict(torch.load(r"trained_model\tomnet.pth"))
    model.eval()  # ä¸å•Ÿç”¨ dropout/batchnorm

    # æ¨è«–ä½¿ç”¨
    num_samples = 10
    alpha = 3
    evaluate_tomnet(model, num_samples, alpha)  # ä½ å‰é¢æ•´åˆçš„æ¨è«–+å¯è¦–åŒ–å‡½æ•¸


def exp_3_1_belief():

    # alpha_mix_dataset = ToMMixtureDataset(num_episodes=1000, alpha_low=0.01, alpha_high=3.0, ratio=0.5, npast=5)
    # alpha_low_dataset = ToMDatasetFlexible(num_episodes=1000, alpha=0.01)
    # alpha_high_dataset = ToMDatasetFlexible(num_episodes=1000, alpha=3.0)

    # === è¨“ç·´éšæ®µ ===
    print("training ToM ...")
    # train_tomnet(alpha_mix_dataset, "tomnet_mix")
    print("finish training mix")
    # train_tomnet(alpha_low_dataset, "tomnet_001")
    print("finish training 0.01")
    # train_tomnet(alpha_high_dataset, "tomnet_3")
    print("finish training 3")

    # å‡è¨­ä½ æœ‰ä¸‰å€‹æ¨¡å‹ï¼š
    model_001 = ToMnet()
    model_001.load_state_dict(torch.load(r"trained_model/tomnet_001.pth"))  # å·²åœ¨ alpha=0.01 ä¸Šè¨“ç·´
    model_001.eval()
    
    model_3 = ToMnet()
    model_3.load_state_dict(torch.load(r"trained_model/tomnet_3.pth"))    # å·²åœ¨ alpha=3 ä¸Šè¨“ç·´
    model_3.eval()
    
    model_mix = ToMnet()
    model_mix.load_state_dict(torch.load(r"trained_model/tomnet_mix.pth"))  # å·²åœ¨æ··åˆ agents ä¸Šè¨“ç·´
    model_mix.eval()

    # ç¹ªåœ–è©•ä¼°ä¸‰è€…åœ¨æ··åˆ agents ä¸Šçš„è¡¨ç¾
    # kl_001_on_mix = evaluate_tomnet_on_mixture(model_001)
    # kl_3_on_mix = evaluate_tomnet_on_mixture(model_3)
    # kl_mix_on_mix = evaluate_tomnet_on_mixture(model_mix)
    # plot_figure3d_kl_bars(kl_001_on_mix, kl_3_on_mix, kl_mix_on_mix)

    # å®šç¾©æ¸¬è©¦ç”¨çš„ alpha å€¼ï¼ˆx è»¸ï¼‰
    test_alphas = [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]

    # åˆ†åˆ¥åœ¨ä¸åŒçš„æ¸¬è©¦ Î± ä¸Šè©•ä¼°ä¸‰å€‹æ¨¡å‹
    kl_001_curve = [evaluate_tomnet_on_mixture(model_001, alpha_low=Î±, alpha_high=Î±) for Î± in test_alphas]
    kl_3_curve =   [evaluate_tomnet_on_mixture(model_3, alpha_low=Î±, alpha_high=Î±) for Î± in test_alphas]
    kl_mix_curve = [evaluate_tomnet_on_mixture(model_mix, alpha_low=Î±, alpha_high=Î±) for Î± in test_alphas]
    plot_figure3d_kl_lines(kl_001_curve, kl_3_curve, kl_mix_curve)


if __name__ == "__main__":

    exp_3_1_grid()

    # exp_3_1_belief()